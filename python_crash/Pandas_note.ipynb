{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe352b7a",
   "metadata": {},
   "source": [
    "1. Importing and exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3905fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data as csv file from cwd\n",
    "df = pd.read_csv('name.csv')\n",
    "\n",
    "# Export data as xlsx files\n",
    "df.to_excel('data_export.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed2716",
   "metadata": {},
   "source": [
    "2. Data manipulation and cleaning\n",
    "The first line drops any rows with missing values from the DataFrame `'df'` using the `dropna()` method with the `inplace=True` parameter. This method removes any rows that contain at least one missing value from the DataFrame.\n",
    "\n",
    "The second line merges two DataFrames 'df1' and 'df2' on the common column `'key'` using the `merge()` method of the Pandas library. The resulting DataFrame `'df_merged'` contains all the columns from `'df1'` and `'df2'` where the values in the `'key'` column match.\n",
    "\n",
    "The third line groups the DataFrame `'df'` by the `'category'` column and aggregates the 'sales' column by summing its values and the 'profit' column by taking the mean of its values using the `groupby()` and `agg()` methods. The resulting DataFrame `'df_grouped'` contains the sum of sales and the mean of profit for each unique category.\n",
    "\n",
    "The fourth line creates a new column `'new_column'` in the DataFrame `'df'` by multiplying the values in columns `'column1'` and `'column2'` element-wise using the `'*'` operator. This is a transformation of the data that adds a new column to the DataFrame.\n",
    "\n",
    "These operations demonstrate the flexibility and power of Pandas for manipulating and transforming data in a variety of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b88b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Merge two data frames\n",
    "df_merged = pd.merge(df1, df2, on='key')\n",
    "\n",
    "# Group and aggregate data\n",
    "df_grouped = df.groupby('category').agg({'sales': 'sum', 'profit': 'mean'})\n",
    "\n",
    "# Transform data\n",
    "df['new_column'] = df['column1'] * df['column2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2675c",
   "metadata": {},
   "source": [
    "3. Data visualization\n",
    "This code uses the Matplotlib library to create three different plots based on the data in the DataFrame `'df'`.\n",
    "\n",
    "The first line imports the Matplotlib library and gives it an alias `'plt'`.\n",
    "\n",
    "The second line creates a line plot with the date on the x-axis and sales on the y-axis using the `plot()` method of the DataFrame. The 'kind' parameter is set to `'line'` to specify the type of plot to create.\n",
    "\n",
    "The third line creates a bar plot with the category on the x-axis and sales on the y-axis using the `plot()` method of the DataFrame. The `'kind'` parameter is set to 'bar' to specify the type of plot to create.\n",
    "\n",
    "The fourth line creates a scatter plot with price on the x-axis and sales on the y-axis using the `plot()` method of the DataFrame. The `'kind'` parameter is set to `'scatter'` to specify the type of plot to create.\n",
    "\n",
    "These plots are useful for visualizing relationships and trends within the data. The line plot shows how sales change over time, the bar plot shows the total sales for each category, and the scatter plot shows how price and sales are related. The plots can be customized with various parameters to improve their appearance and convey information more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a line plot\n",
    "df.plot(x='date', y='sales', kind='line')\n",
    "\n",
    "# Create a bar plot\n",
    "df.plot(x='category', y='sales', kind='bar')\n",
    "\n",
    "# Create a scatter plot\n",
    "df.plot(x='price', y='sales', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe83db7",
   "metadata": {},
   "source": [
    "4. Descriptive statistics\n",
    "\n",
    "This code section computes the mean and median of the 'sales' column in the DataFrame 'df'. It then computes the correlation coefficient between the 'sales' and 'price' columns in the same DataFrame.\n",
    "\n",
    "The first line calculates the mean of the 'sales' column using the ```mean()``` method, which returns the average value of the column.\n",
    "\n",
    "The second line calculates the median of the 'sales' column using the ```median()``` method, which returns the middle value of the column when it is sorted in ascending order.\n",
    "\n",
    "The third line computes the correlation coefficient between the 'sales' and 'price' columns using the ```corr()``` method of the DataFrame. The ```.iloc[0, 1]``` at the end of the line extracts the value of the correlation coefficient from the resulting DataFrame, which is the value in the first row and second column.\n",
    "\n",
    "The correlation coefficient is a measure of the strength and direction of the linear relationship between two variables. A value of 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and median\n",
    "mean_sales = df['sales'].mean()\n",
    "median_sales = df['sales'].median()\n",
    "\n",
    "# Compute correlation coefficient\n",
    "corr_coeff = df[['sales', 'price']].corr().iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738519b7",
   "metadata": {},
   "source": [
    "5. Time series analysis\n",
    "\n",
    "This code performs several operations on the DataFrame `'df'` related to time series analysis.\n",
    "\n",
    "The first line converts the 'date' column to a datetime data type using the `to_datetime()` method of the Pandas library. This method converts a column containing dates or times represented as strings or other data types to a Pandas datetime data type, which allows for easier manipulation and analysis of the time series data.\n",
    "\n",
    "The second line resamples the data in `'df'` to a monthly frequency using the `resample()` method with the argument `'M'` to specify monthly frequency and 'on' parameter set to 'date' to indicate the column to use for the resampling operation. The `sum()` method is then called to compute the sum of the sales for each month. The resulting DataFrame `'df_monthly'` contains the total sales for each month.\n",
    "\n",
    "The third line computes the rolling window average of the 'sales' column in the DataFrame `'df'` using the `rolling()` method with the parameter `'window=7'` to specify a window size of 7 days. The `.mean()` method is then called to compute the mean of the values in the window for each row. The resulting values are added to a new column `'rolling_avg'` in the DataFrame `'df'`.\n",
    "\n",
    "These operations are useful for analyzing time series data by converting the date column to a datetime format, resampling the data to a desired frequency, and computing rolling window averages to smooth out fluctuations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482cb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime data type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Resample data to monthly frequency\n",
    "df_monthly = df.resample('M', on='date').sum()\n",
    "\n",
    "# Compute rolling window average\n",
    "df['rolling_avg'] = df['sales'].rolling(window=7).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11ec1e",
   "metadata": {},
   "source": [
    "6. Data preparation for machine learning\n",
    "\n",
    "This code performs several preprocessing steps on a dataset using `scikit-learn` and Pandas libraries.\n",
    "\n",
    "The first two lines import the necessary modules from `scikit-learn` to split the data into training and test sets using the `train_test_split()` method. The method takes the input features X and target variable y as arguments along with a test size of 0.2 to specify that 20% of the data should be reserved for testing.\n",
    "\n",
    "The next two lines create an instance of `StandardScaler()` from `scikit-learn` and use it to normalize the training and test sets separately. The `fit_transform()` method of the scaler object is used to fit the scaler to the training data and transform it, while the `transform()` method is used to transform the test data using the scaling parameters learned from the training data. This is a common preprocessing step in machine learning to ensure that all features are on a similar scale, which can improve the performance of certain models.\n",
    "\n",
    "The last line uses the `pd.get_dummies()` method of the Pandas library to one-hot encode categorical variables in the training set. One-hot encoding converts a categorical variable with n possible values into n binary variables, each of which represents one possible value. This is useful for certain models that cannot handle categorical variables directly. The columns parameter specifies which columns to one-hot encode in the training set.\n",
    "\n",
    "These preprocessing steps prepare the data for use in a machine learning model by splitting it into training and test sets, normalizing the features, and one-hot encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc047a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bada4b",
   "metadata": {},
   "source": [
    "7. Groupby, Pivot tables, and Crosstabs\n",
    "\n",
    "This code performs three different types of data analysis using the Pandas library.\n",
    "\n",
    "The first line uses the `groupby()` method of a Pandas DataFrame to group the data by a categorical variable category. The `agg()` method is then used to compute the sum of the sales column and the mean of the profit column for each group. This creates a new DataFrame `df_grouped` that has one row for each unique value of category and two columns with the aggregated statistics.\n",
    "\n",
    "The second line uses the `pd.pivot_table()` method to create a pivot table that summarizes the data by two variables: category and date. The values parameter specifies that we want to sum the sales column for each combination of category and date. The resulting pivot table `df_pivot` has one row for each unique value of category and one column for each unique value of date. The cells of the pivot table contain the sum of the sales column for each combination of category and date.\n",
    "\n",
    "The third line uses the `pd.crosstab()` method to create a contingency table, also known as a cross-tabulation, that shows the frequency distribution of two categorical variables: category and color. The resulting table shows the count of each combination of category and color. This is useful for analyzing relationships between two categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d853ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby\n",
    "df_grouped = df.groupby('category').agg({'sales': 'sum', 'profit': 'mean'})\n",
    "\n",
    "# Pivot tables\n",
    "df_pivot = pd.pivot_table(df, index='category', columns='date', values='sales', aggfunc='sum')\n",
    "\n",
    "# Crosstabs\n",
    "pd.crosstab(df['category'], df['color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec71e45",
   "metadata": {},
   "source": [
    "8. Data merging and joining\n",
    "\n",
    "This code demonstrates how to combine two or more Pandas DataFrames using the `merge()` and `concat()` functions.\n",
    "\n",
    "The `merge()` function is used to combine two DataFrames based on a common column, called the `\"key\"`. In the first line, `df1` and `df2` are merged into a new DataFrame df_merged, based on the common column `'key'`. This creates a new DataFrame that contains all the columns from `df1` and `df2` where the values in the `'key'` column match.\n",
    "\n",
    "The `merge()` function can also be used to perform left, right, and outer joins. In the second line, a left join is performed by specifying the `how='left'` parameter. This creates a new DataFrame `df_left` that contains all the rows from `df1` and only the matching rows from `df2`.\n",
    "\n",
    "The `concat()` function is used to concatenate two or more DataFrames vertically or horizontally. In the third line, df1 and df2 are concatenated vertically using `pd.concat()`. This creates a new DataFrame df_concat that has all the rows from df1 followed by all the rows from `df2`. Note that the `concat()` function assumes that the column names and data types match across the DataFrames being concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa612e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data frames\n",
    "df_merged = pd.merge(df1, df2, on='key')\n",
    "\n",
    "# Left join\n",
    "df_left = pd.merge(df1, df2, on='key', how='left')\n",
    "\n",
    "# Concatenate data frames\n",
    "df_concat = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc293dae",
   "metadata": {},
   "source": [
    "9. Time Series analysis\n",
    "\n",
    "This code demonstrates some time-series operations that can be performed on a Pandas DataFrame that has a datetime column.\n",
    "\n",
    "The first line converts the date column of the DataFrame df to a datetime data type using the `pd.to_datetime()` function.\n",
    "\n",
    "The second line resamples the DataFrame to monthly frequency using the `resample()` method. Here, the `on='date'` argument specifies the column to resample, and the `'M'` argument indicates that the resampling frequency should be monthly. The `.sum()` method specifies that we want to aggregate the data by summing the values of each month. The result is a new DataFrame df_monthly that has the same columns as the original DataFrame df, but with the data aggregated to monthly frequency.\n",
    "\n",
    "The third line computes a rolling window average of the `'sales'` column of the DataFrame. The `.rolling()` method creates a rolling window of the specified size (7 days in this case) over the data, and the `.mean()` method computes the mean of the values in the window. The result is a new column `rolling_avg` that contains the rolling window averages for the `'sales'` column. This can be useful for identifying trends and smoothing out noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63541865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime data type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Resample data to monthly frequency\n",
    "df_monthly = df.resample('M', on='date').sum()\n",
    "\n",
    "# Compute rolling window average\n",
    "df['rolling_avg'] = df['sales'].rolling(window=7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ab648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe769c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
